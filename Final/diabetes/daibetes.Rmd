---
title: "Agrupamento com K-means sobre dados Médicos"
author: "Marcos Vinícius dos Santos Ferreira"
date: '2018-04-16'
output:
  html_document:
    number_sections: yes
    toc: yes
  pdf_document:
    toc: yes
---

# Database Diabetes
## Diabetes 130-US hospitals for years 1999-2008 Data Set 

Estes dados foram preparados para analisar os fatores relacionados à readmissão, bem como outros resultados referentes aos pacientes com diabetes.

### Informação do dataset
  O conjunto de dados representa 10 anos (1999-2008) de atendimento clínico em 130 hospitais dos EUA e redes de distribuição integradas. Inclui mais de 50 atributos multivariados que representam os resultados do paciente e do hospital. O dataset contém 100000 instâncias. Informações foram extraídas do banco de dados para encontros que satisfizeram os seguintes critérios.
  
    1. É um encontro de internação (internação hospitalar).
    2. É um encontro diabético. 
    3. O tempo de internação foi de no mínimo 1 dia e no máximo 14 dias.
    4. Testes laboratoriais foram realizados durante o encontro.
    5. Medicamentos foram administrados durante o encontro.

Os dados contêm atributos como número do paciente, raça, gênero, idade, tipo de internação, tempo no hospital, especialidade médica do médico admitido, número de exames laboratoriais realizados, resultado do exame de HbA1c, diagnóstico, número de medicamentos, medicamentos diabéticos, número de pacientes ambulatoriais , internação e visitas de emergência no ano anterior à hospitalização, etc.


### Dificuldades Aprensentadas:
  * Heterogêneas e difíceis em termos de valores ausentes
  * Registros incompletos ou inconsistentes
  * Alta dimensionalidade, entendida pelo número de características e  por sua complexidade.

# Paper
## Impact of HbA1c Measurement on Hospital Readmission Rates: Analysis of 70,000 Clinical Database Patient Records

  * Impacto da Medida de HbA1c nas Taxas de Readmissão Hospitalar: Análise de 70.000 Registros de Pacientes com Base de Dados Clínicos.
  * **Hipótesi:** Nossa hipótese é que a medida da HbA1c está associada a uma redução nas taxas de readmissão em indivíduos internados no hospital.
  
# Minha Contribuição
Fazer o uso do aprendizado de máquina não supervisionado para identificar relação entre dados clínicos de diabetes e fornecer 
indícios de quais fatores influenciam mais na doença, para então descrever quantos níveis da doença podem existir entre os pacientes.

## Objetivo
  * Quais fatores influenciam e ou apontam indícios sobre o avanço ou cura da da diabete, e quantos níveis da doença podem ser descritos?
  
## Metodos
  * Usar o Aprendizado de Máquina não supervisionado com o algoritmo k-means para indentificar padrões que possam identificar padrões no dataset que evidenciam tais indícios.
  
## Hipótese de quais fatores mais influenciam no diabetes(avanço da doença).

| Atributo  | Tipo  | Valores Ausentes(%)  |
|---|---|---|
| Idade  | Nominal |  0 |
| Discharge disposition  | Nominal  | 0 |
| Admission source  | Nominal  | 0 |
| Time in hospital  | Numeric  |  0 |
| Medical specialty  | Nominal  |  59 |
| Number of lab procedures  | Numeric  | 0 |
| Number of procedures  | Numeric  | 0 |
| Number of medications  | Numeric  | 0 |
| Number of emergency visits  | Numeric  | 0 |
| Diagnosis 1  | Nominal  | 0 |
| Diagnosis 2  | Nominal  | 0 |
| Diagnosis 3  | Nominal  | 1 |
| Número de Diagnósticos  |  Numeric |0 |
| Glucose serum test result  | Nominal | 1 |


## Carregando os dados
```{r message=FALSE}
# lendo o dataset
data.diabetes <- read.csv('../../data/dataset_diabetes/diabetic_data.csv')

# Visualizando o dataset
str(data.diabetes)
```
## Pré-Processamento

```{r message=FALSE}

# selecionar os atributos que por hipótese podem ser relevantes
data.diabetes.rel <- data.diabetes[,c('age', 'discharge_disposition_id', 'admission_source_id',
                                      'time_in_hospital', 'medical_specialty', 'num_lab_procedures', 'num_procedures',
                                      'num_medications', 'number_outpatient', 'diag_1', 'diag_2', 'diag_3',
                                      'number_diagnoses', 'max_glu_serum')]

# estrutura dos novos dados
str(data.diabetes.rel)
```

```{r}

# selecionar as 200 primeiras instancias

data.diabetes.rel.sel <- data.diabetes.rel[1:200,]

str(data.diabetes.rel.sel)
```

```{r}
# tranformar as colunas de palavras em numeros
med.esp <-as.numeric(data.diabetes.rel.sel$medical_specialty)

data.diabetes.rel.sel['medical_specialty'] <- as.integer(med.esp)

str(data.diabetes.rel.sel)
```

```{r}
# dados de idade

data.diabetes.rel.sel$age

```
Tratando os valores de diagnostico.
```{r}
# função que troca de valores
troca.valor<-function(estrutura, valor, troca){

  temp <- as.vector(estrutura)
  
  temp[which(temp==valor)]=troca

  temp
}

data.diabetes.rel.sel$age <- troca.valor(data.diabetes.rel.sel$age,"[0-10)", "10")
data.diabetes.rel.sel$age <- troca.valor(data.diabetes.rel.sel$age,"[10-20)", "15")
data.diabetes.rel.sel$age <- troca.valor(data.diabetes.rel.sel$age,"[20-30)", "25")
data.diabetes.rel.sel$age <- troca.valor(data.diabetes.rel.sel$age,"[30-40)", "35")
data.diabetes.rel.sel$age <- troca.valor(data.diabetes.rel.sel$age,"[40-50)", "45")
data.diabetes.rel.sel$age <- troca.valor(data.diabetes.rel.sel$age,"[50-60)", "55")
data.diabetes.rel.sel$age <- troca.valor(data.diabetes.rel.sel$age,"[60-70)", "65")
data.diabetes.rel.sel$age <- troca.valor(data.diabetes.rel.sel$age,"[70-80)", "75")
data.diabetes.rel.sel$age <- troca.valor(data.diabetes.rel.sel$age,"[80-90)", "85")
data.diabetes.rel.sel$age <- troca.valor(data.diabetes.rel.sel$age,"[90-100)", "95")

# vendoos valores convertidos pela media de idades
data.diabetes.rel.sel$age
```
```{r}
# convertendo os nuvemos para interios
data.diabetes.rel.sel$age <- as.integer(data.diabetes.rel.sel$age)

data.diabetes.rel.sel$age
```
vendo a distribuição dos valores com o histograma.
```{r}
hist(data.diabetes.rel.sel$age)
```


```{r}

# tratar valores nulos dos diagnóstico - solução - média.

# visualizando os dados dos 3 dianosticos
par(mfrow=c(3,1))
plot(data.diabetes.rel.sel$diag_1, main='diagnóstico 1')
plot(data.diabetes.rel.sel$diag_2, main='diagnóstico 2')
plot(data.diabetes.rel.sel$diag_3, main='diagnóstico 3')
```
```{r}
#tratar valores desconhecidos - ?
## possso remover esses valores ou aplicar um media
head(data.diabetes.rel.sel$diag_1)
```
```{r}
# solution 1
# data.diabetes.rel.sel$diag_1 <- troca.valor(data.diabetes.rel.sel$diag_1,'?', 414)
# data.diabetes.rel.sel$diag_1 <- as.integer(data.diabetes.rel.sel$diag_1)
# data.diabetes.rel.sel$diag_1[is.na(data.diabetes.rel.sel$diag_1)] <- 0
# data.diabetes.rel.sel$diag_1

# solution 2
# temp <- troca.valor(data.diabetes.rel.sel$diag_1,'?', 414)
# temp <- as.integer(temp)
# temp[is.na(temp)] <- 0
# hist(temp)

# solution 3
# diagnostico 1
data.diabetes.rel.sel$diag_1 <- as.integer(data.diabetes.rel.sel$diag_1)
data.diabetes.rel.sel$diag_1[is.na(data.diabetes.rel.sel$diag_1)] <- 0

# diagnostico 2
data.diabetes.rel.sel$diag_2 <- as.integer(data.diabetes.rel.sel$diag_2)
data.diabetes.rel.sel$diag_2[is.na(data.diabetes.rel.sel$diag_2)] <- 0

# diagnostico 3
data.diabetes.rel.sel$diag_3 <- as.integer(data.diabetes.rel.sel$diag_3)
data.diabetes.rel.sel$diag_3[is.na(data.diabetes.rel.sel$diag_3)] <- 0

# visualizando os dados
par(mfrow=c(3,1))
hist(data.diabetes.rel.sel$diag_1, main='diagnóstico 1')
hist(data.diabetes.rel.sel$diag_2, main='diagnóstico 2')
hist(data.diabetes.rel.sel$diag_3, main='diagnóstico 3')

```
```{r}
# conferindo a nova estrutura do dataset
str(data.diabetes.rel.sel)
```

```{r}
# removendo a coluna max_glu_serum por ter muitos valores discrepantes 
data.diabetes.rel.sel = subset(data.diabetes.rel.sel, select = -c(max_glu_serum))
```
## Análise dos dados

Primeiro temos que explorar e visualizar os dados.
```{r}
# estrutura dos meus dados
str(data.diabetes.rel.sel)
```

Todas as colunas são expressas como numéricas ou inteiras. E quanto à distribuição estatística?
```{r}
summary(data.diabetes.rel.sel)
```
```{r message=FALSE, warning=FALSE}

#load library
library(tidyverse)
library(corrplot)
library(gridExtra)
library(GGally)

# Histograma de cada atributo

data.diabetes.rel.sel %>%
  gather(Attributes, value, 1:13) %>%
  ggplot(aes(x=value)) +
  geom_histogram(fill="lightblue2", colour="black") +
  facet_wrap(~Attributes, scales="free_x") +
  labs(x="Values", y="Frequency") 
```

Qual é a relação entre os diferentes atributos? Podemos usar a função **corrplot()** para criar uma exibição gráfica de uma matriz de correlação.

```{r message=FALSE, warning=FALSE}
# Matrix de correlação - pie(boa representação)
corrplot(cor(data.diabetes.rel.sel), type="upper", method="pie", tl.cex=0.9)
```

Existe uma forte correlação linear entre os atributos: 
  
  * _discharge-disposition-id_ e _medical-specialty_
  * _num-medications_  e _time-in-hospital_
  * _num-medications_ e _num-procedures_
  * _num-medications_ e _number-diagnoses_
  * _admission-source-id_ e _num-procedures_
  

  
Podemos modelar a relação entre essas duas variáveis ajustando uma equação linear.

```{r message=FALSE, warning=FALSE}
# Relacionamento entre as variaveis que mais tem correlação

# discrarge disposition id & médico especialista
plt1 <- ggplot(data.diabetes.rel.sel, aes(x=discharge_disposition_id, y=medical_specialty)) +
  geom_point() +
  geom_smooth(method="lm", se=FALSE)

# tempo em hospital & numero de medicamentos 
plt2 <- ggplot(data.diabetes.rel.sel, aes(x=time_in_hospital, y=num_medications)) +
  geom_point() +
  geom_smooth(method="lm", se=FALSE)

# número de procedimentos e numero de medicamentos medications
plt3 <- ggplot(data.diabetes.rel.sel, aes(x=num_procedures, y=num_medications)) +
  geom_point() +
  geom_smooth(method="lm", se=FALSE)

# numbero de diagnosticos e numero de medicações
plt4 <- ggplot(data.diabetes.rel.sel, aes(x=number_diagnoses, y=num_medications)) +
  geom_point() +
  geom_smooth(method="lm", se=FALSE)

grid.arrange(plt1, plt2, plt3, plt4,  ncol=2, nrow=2)
#grid.arrange(plt1, plt2, plt3, plt4, nrow=2 , col=2)
```

A correlação linear se aplica fortemente entre as variáveis _num-medications_, _time-in-hospital_, 
_discharge-disposition-id_, _medical-specialty_, _num-procedures_, _number-diagnoses_, e  _admission-source-id_.  **Esses atributos fortemene ligados, podem nos levar a inferir descrições sobre os  dados, ou seja, podemos conferir por exemplo a hipótesi de quantos níveis de diabetes as pessoas que estão realizando esse tratamento possuem.**

Agora que fizemos uma análise de dados exploratória, podemos descrever os dados ao encontrar grupos que compartilham padrões semelhantes, para tal, utilizaremos o algoritmo particional **K-means**, segundo mais importante na área de mineração de dados. Podemos preparar os dados para executar o algoritmo k-means.

## Preparação dos dados

Temos que normalizar as variáveis para expressá-las no mesmo intervalo de valores. Em outras palavras, normalização significa ajustar os valores medidos em diferentes escalas para uma escala comum.

```{r message=FALSE, warning=FALSE}
# após analisar os atributos que podem possuem maior relação, os mesmos 
# são selecionados para inferir melhor os resultados.

# criar uma nova variavel para receber as novas 

  # ------- dados que serao utilizados --------
  #  discharge_disposition_id *
  #  medical_specialty **
  #  num_medications
  #  time_in_hospital
  #  num_procedures
  #  number_diagnoses
  #  admission_source_id

# selecionando os atributos que podem inferir hipóteses relevantes
data.diabetes.rel.sel.new <-data.diabetes.rel.sel[,c('discharge_disposition_id', 'admission_source_id',
                                      'time_in_hospital', 'medical_specialty', 'num_procedures',
                                      'num_medications' , 'number_diagnoses')]

# atributos selecionados
data.diabetes.rel.sel.new.norm <- as.data.frame(scale(data.diabetes.rel.sel.new))


# dados originais sem normalização
data <- ggplot(data.diabetes.rel.sel.new,
               aes(x=num_medications + medical_specialty  ,
                   y=time_in_hospital + num_procedures + number_diagnoses + medical_specialty)) +
  geom_point() +
  labs(title="Dados originais")

# dados normalizados
data.norm <- ggplot(data.diabetes.rel.sel.new.norm,
               aes(x=num_medications + medical_specialty,
                   y=time_in_hospital + num_procedures + number_diagnoses + medical_specialty)) +
  geom_point() +
  labs(title="Dados normalizados")

# subplot
grid.arrange(data,data.norm, ncol=2)
```




## Quantos Clustes ?

Para o algoritmo K-means encontrar similiaridade entre os grupos, precisa do parâmetro **k**, que é a quantidade de grupos a serem escolhidos. Utiliza-se o método do cotovelo que testa a variância dos dados em relação ao número de clusters. Ele testa até o momento que conforme o número de clustes aumenta não representa um valor significativo de ganho. Podemos ver o formato de um cotovelo ao plotar os resultados em uma gráfico e  partir do valor indicado pelo _cotovelo_ no gráfico significa que não existe ganho em relação ao aumento de clusters. Antes mesmo, visualizamos o conjunto de dados selecionado ate o momento. 

```{r}
# Vendo os dados

ggplot(data.diabetes.rel.sel.new.norm,
               aes(x=num_medications + medical_specialty,
                   y=time_in_hospital + num_procedures + number_diagnoses + medical_specialty)) +
  geom_point() +
  labs(title="Dados normalizados")

```


Qual é o valor ideal para k? Deve-se escolher um número de clusters para que adicionar outro cluster não forneça uma partição muito melhor dos dados. Em algum momento, o ganho cairá, dando um ângulo no gráfico (critério do cotovelo). O número de clusters é escolhido neste momento. No nosso caso, é claro que 3 é o valor apropriado para k. Para estudar graficamente qual valor de k nos dá a melhor partição, podemos traçar entre e tot.withinss vs Choice de k.

```{r message=FALSE, warning=FALSE}
bss <- numeric()
wss <- numeric()

# rodar o algoritmo com diferentes valores de K
set.seed(1234)

for(i in 1:10){
  
  # para casa k, calcula betweenss e tot.withinss
  bss[i] <- kmeans(data.diabetes.rel.sel.new.norm, centers=i)$betweenss
  wss[i] <- kmeans(data.diabetes.rel.sel.new.norm, centers=i)$tot.withinss
}

# Soma entre os quadrados dos quadrados vs Escolha de k

d3 <- qplot(1:10, bss, geom=c("point", "line"), 
            xlab="Number of clusters", ylab="Between-cluster sum of squares") +
  scale_x_continuous(breaks=seq(0, 10, 1))

# Soma total de quadrados dentro do cluster vs Escolha de k

d4 <- qplot(1:10, wss, geom=c("point", "line"),
            xlab="Number of clusters", ylab="Total within-cluster sum of squares") +
  scale_x_continuous(breaks=seq(0, 10, 1))

# subplot
grid.arrange(d3, d4, ncol=2)
```

## Execução do k-means

Com o algoritmo k-means identificamos a quantidade de grupos que meus dados formam e com isso podemos trazer semântica aos dados e tirar conclusões. De acordo com o método do cotovelo, a quantidade de clusters é igual 3, ou seja, o meu parâmetro **k**.

```{r}

# selecionar somente os atributos de clusters
#data.diabetes.rel.sel.new.norm <- data.diabetes.rel.sel.new.norm[,c('time_in_hospital', 'num_medications')]

# Execução do K-means com k  = 6
set.seed(1234)
kmenas.diabetes <- kmeans(data.diabetes.rel.sel.new.norm, centers=3, nstart = 100)
```
  
  *Vetor de inteiros indicando o custer ao qual cada ponto é alocado. 
  
```{r}
kmenas.diabetes$cluster
```
 A matriz com o centro dos clusters.
```{r}
kmenas.diabetes$centers
```
Visualizando o agrupamento.

```{r}

# melhorar os labels do meu grafico
kmenas.diabetes$cluster <- as.factor(kmenas.diabetes$cluster)

p1 <- ggplot(data.diabetes.rel.sel.new.norm,
             aes(
               x=num_medications + medical_specialty,
               y=time_in_hospital + num_procedures + number_diagnoses + medical_specialty,
               color = kmenas.diabetes$cluster)) +
      geom_point() +
      xlab(" Medicamentos e Especialista") +
      ylab(" Tempo no Hospital e Num Procedimentos") +
      labs(title=" Agrupamento Particional dos Dados ")

p1
```

## Redução de Dimensionalidade

O conjunto de dados, mesmo com a seleção manual dos atributos e visualização, ainda se tem como hipótesi alguns atributos que juntos podem inferir melhores resultados. Para diminuir o custo e aumentar a precisão do cluster, uma alternativa é aplica a redução de dimensionalidade. Uma técnica muito comum utilizada é o Principal Component Analysis.

### Principal Component Analysis - PCA

  * Método que utiliza uma transformação ortogonal para converter um conjunto de observações correlacionadas em um conjunto de componentes principais (observações linearmente não-correlacionadas).  São formadas combinações lineares das variáveis observadas e gerados componentes componentes na mesma quantidade de atributos, sendo que: 
    * O primeiro componente principal consiste na combinação que responde pela maior quantidade de variância na amostra.
    * O segundo componente responde pela segunda maior variância na amostra e não é correlacionado com o primeiro componente.
    * Sucessivos componentes explicam progressivamente menores porções de variância total da amostra e todos são não correlacionados uns aos outros.

```{r}
# aplica o PCA - scale = TRUE é aconselhavel
# mas o padrão é false
data.diabetes.rel.sel.new.norm.pca <- prcomp(data.diabetes.rel.sel.new.norm, center = TRUE, scale. = TRUE)

data.diabetes.rel.sel.new.norm.pca
```


```{r message=FALSE, warning=FALSE}
library(ggbiplot)
ggbiplot(data.diabetes.rel.sel.new.norm.pca, obs.scale = 1, var.scale = 1,
   ellipse = TRUE, circle = TRUE) +
  scale_color_discrete(name = '') +
  theme(legend.direction = 'horizontal', legend.position = 'top')
```

Os dois primeiros componentes descrevem 52,6% da variancia da amostra.

Visualizado os grupos formados com o meu cluster.

 
```{r}
library(ggplot2)
# colletando os dados
tmp_d = data.frame(matrix(ncol=0, nrow=nrow(data.diabetes.rel.sel.new.norm)))
tmp_d$cluster = as.factor(kmenas.diabetes$cluster)
tmp_d$fact_1 = as.numeric(data.diabetes.rel.sel.new.norm.pca$x[, 1])
tmp_d$fact_2 = as.numeric(data.diabetes.rel.sel.new.norm.pca$x[, 2])
tmp_d$label = rownames(data.diabetes.rel.sel.new.norm)

# visualizando o agrupamento depois da reduçao de dimensionalidade
ggplot(tmp_d, aes(fact_1, fact_2, color = cluster)) +
    geom_point() 

```
 
Visulizando a quantidade de elementos que cada centroide agrupou. 

```{r}
kmenas.diabetes$cluster%>%
  table()%>%
  barplot(main="Frequências dos clusters", names.arg=c("Cluster 1", "Cluster 2", "Cluster 3"))
```


# Validação

Aqui validamos o quão o método conseguio agrupar conforme um índice de validação. Validar com critérios internos, pois vai medir a qualidade do agrupamento com base nos dados originais, ja que, os dados não posuem rótulos ou  estruturas definidas.

  * **Critério Interno**
    * Mede o grau que uma partição obtida representa a estrutura presente nos dados;

# Consusão 

  * Os grupos podem indicar a variedade do estado de saúde das pessoas com diabétes, ou seja, com diferentes graus, leve, moderado, normal, grave e diabete melitus.
  * Os vastos grupos indicam que o tratamento merece mais cuidados.
  * Pode-se concluir que diante das diversas características dos paciente, a readmissão dos pacientes acontecem nos mais diversos casos da diabete, é uma doença severa e que merece uma atenção e tratamento adequado, sendo grande parte resposável o própio paciente a seus limites. 

# Referências
  * [Introdução ao Aprendizado de Máquina](https://medium.com/@avinicius.adorno/introdu%C3%A7%C3%A3o-a-aprendizado-de-m%C3%A1quina-e39ec5ef459b)
  * [Origem do Dataset](https://archive.ics.uci.edu/ml/datasets/Diabetes+130-US+hospitals+for+years+1999-2008)
  * [Descrição dos Atributos ](https://www.hindawi.com/journals/bmri/2014/781670/tab1/)
  * [Silhueta](http://www.sthda.com/english/rpkgs/factoextra/reference/fviz_silhouette.html)
  * [Indroduction Data Mining](https://github.com/mhahsler/Introduction_to_Data_Mining_R_Examples/blob/master/chap8.R)
  * [Chapter 8](https://rawgit.com/mhahsler/Introduction_to_Data_Mining_R_Examples/master/chap8.html)

  